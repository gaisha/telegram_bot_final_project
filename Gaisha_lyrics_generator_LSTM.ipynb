{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IA5JgoQhXhpB"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtjKCzB1XhpF"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import string, os\n",
        "import nltk\n",
        "import re\n",
        "import keras\n",
        "import random\n",
        "import io\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adamax\n",
        "import sys\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Mh9gRExXhpF"
      },
      "source": [
        "<a id=\"2\"></a>\n",
        "# <p style=\"background-color:#B291B6;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 60px;\">LOADING DATA</p>\n",
        "For this project, I have prepared a dataset of song lyrics. Let's load it and have a look."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYwEzZ8xXhpG"
      },
      "source": [
        "<a id=\"3\"></a>\n",
        "# <p style=\"background-color:#B291B6;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 60px;\">DATA EXPLORATION</p>\n",
        "\n",
        "**In this section, I will be:**\n",
        "* Exploring the various artists in data\n",
        "* Explore the number of songs and their corresponding information\n",
        "* Explore the various words in lyrics via wordcloud "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMErl0jsXhpH"
      },
      "source": [
        "So I have a total of 745 songs\n",
        "\n",
        "**I will do a little feature engineering to extract more information on the songs such as:**\n",
        "* Number of characters\n",
        "* Number of words\n",
        "* Number of lines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "mR4q8SgO0_CJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab519ab-e65d-482d-a3aa-acd43ea800de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qF9MTqyu8RVv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "bd07a5c3-5a50-4d24-a1f2-d0fb3ea66e83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Lyric  \\\n",
              "0  Kara bulutlar sardГ„В± yine dГѓВјnyamГ„В±\\nKГ„...   \n",
              "1  Dolunay parlak gГѓВ¶rГѓВјnmГѓВјyor bu gece\\nBe...   \n",
              "2  Ay Г„В±Г…ВџГ„В±Г„ВџГ„В±nГ„В±n altГ„В±nda\\nYaln...   \n",
              "3  Ay Г„В±Г…ВџГ„В±Г„ВџГ„В±nГ„В±n altГ„В±nda\\nYaln...   \n",
              "4  YГѓВјrГѓВјyorum yalnГ„В±z baГ…ВџГ„В±ma\\nNereye...   \n",
              "\n",
              "                                           Lyric_STR  No_of_Characters  \\\n",
              "0  Kara bulutlar sardГ„В± yine dГѓВјnyamГ„В±\\nKГ„...               277   \n",
              "1  Dolunay parlak gГѓВ¶rГѓВјnmГѓВјyor bu gece\\nBe...               471   \n",
              "2  Ay Г„В±Г…ВџГ„В±Г„ВџГ„В±nГ„В±n altГ„В±nda\\nYaln...               660   \n",
              "3  Ay Г„В±Г…ВџГ„В±Г„ВџГ„В±nГ„В±n altГ„В±nda\\nYaln...               660   \n",
              "4  YГѓВјrГѓВјyorum yalnГ„В±z baГ…ВџГ„В±ma\\nNereye...               516   \n",
              "\n",
              "   Contains_letter Lyric_detected_language  \n",
              "0             True                      tr  \n",
              "1             True                      tr  \n",
              "2             True                      tr  \n",
              "3             True                      tr  \n",
              "4             True                      tr  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d24a5f6c-f284-4a23-8503-099e3008de9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lyric</th>\n",
              "      <th>Lyric_STR</th>\n",
              "      <th>No_of_Characters</th>\n",
              "      <th>Contains_letter</th>\n",
              "      <th>Lyric_detected_language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kara bulutlar sardГ„В± yine dГѓВјnyamГ„В±\\nKГ„...</td>\n",
              "      <td>Kara bulutlar sardГ„В± yine dГѓВјnyamГ„В±\\nKГ„...</td>\n",
              "      <td>277</td>\n",
              "      <td>True</td>\n",
              "      <td>tr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dolunay parlak gГѓВ¶rГѓВјnmГѓВјyor bu gece\\nBe...</td>\n",
              "      <td>Dolunay parlak gГѓВ¶rГѓВјnmГѓВјyor bu gece\\nBe...</td>\n",
              "      <td>471</td>\n",
              "      <td>True</td>\n",
              "      <td>tr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ay Г„В±Г…ВџГ„В±Г„ВџГ„В±nГ„В±n altГ„В±nda\\nYaln...</td>\n",
              "      <td>Ay Г„В±Г…ВџГ„В±Г„ВџГ„В±nГ„В±n altГ„В±nda\\nYaln...</td>\n",
              "      <td>660</td>\n",
              "      <td>True</td>\n",
              "      <td>tr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ay Г„В±Г…ВџГ„В±Г„ВџГ„В±nГ„В±n altГ„В±nda\\nYaln...</td>\n",
              "      <td>Ay Г„В±Г…ВџГ„В±Г„ВџГ„В±nГ„В±n altГ„В±nda\\nYaln...</td>\n",
              "      <td>660</td>\n",
              "      <td>True</td>\n",
              "      <td>tr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>YГѓВјrГѓВјyorum yalnГ„В±z baГ…ВџГ„В±ma\\nNereye...</td>\n",
              "      <td>YГѓВјrГѓВјyorum yalnГ„В±z baГ…ВџГ„В±ma\\nNereye...</td>\n",
              "      <td>516</td>\n",
              "      <td>True</td>\n",
              "      <td>tr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d24a5f6c-f284-4a23-8503-099e3008de9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d24a5f6c-f284-4a23-8503-099e3008de9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d24a5f6c-f284-4a23-8503-099e3008de9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Detecting language took a lot of time. I am saving it as new csv file for future \n",
        "# data.to_csv('data_17NOV.csv', index=False)\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/NLP_learning/data_with_language.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5zjXxDX7WVg2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "33292bfd-3560-4753-bc9a-435e9b10573c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Lyric  \\\n",
              "7                                    [GGFH cover]\\n\\n   \n",
              "8   [Originally performed by Bloodthorn]\\n\\nDrops ...   \n",
              "9   Electro eroticism\\nIntelligence is sexy\\nElect...   \n",
              "10  Inhale/exhale\\nInhale the exhaled\\nInhale/exha...   \n",
              "11  Under the dark sky we stand\\nUnder heavy rain ...   \n",
              "12  Seducer sun shine on me\\nFamiliar scene, fever...   \n",
              "13  The black iris devours pictures in silence\\nTh...   \n",
              "14  Night swells to distant spheres\\nSilent throat...   \n",
              "15  Opulent kinetic sculptures\\nVisualized voices ...   \n",
              "18  The nights fall and skies fall\\nDown here we t...   \n",
              "19  The light of the sun - is so cold down here\\nM...   \n",
              "20  I love this world\\nAnd these people, the beaut...   \n",
              "21  There lies a body: cold, bloated and empty\\nLi...   \n",
              "22  Touch me!\\nI am a disease!\\nClean me!\\nImpriso...   \n",
              "23  Savour!\\nThe things that never were!\\nEscape!\\...   \n",
              "\n",
              "                                            Lyric_STR  No_of_Characters  \\\n",
              "7                                    [GGFH cover]\\n\\n                14   \n",
              "8   [Originally performed by Bloodthorn]\\n\\nDrops ...               685   \n",
              "9   Electro eroticism\\nIntelligence is sexy\\nElect...               539   \n",
              "10  Inhale/exhale\\nInhale the exhaled\\nInhale/exha...               502   \n",
              "11  Under the dark sky we stand\\nUnder heavy rain ...               838   \n",
              "12  Seducer sun shine on me\\nFamiliar scene, fever...               551   \n",
              "13  The black iris devours pictures in silence\\nTh...               722   \n",
              "14  Night swells to distant spheres\\nSilent throat...               739   \n",
              "15  Opulent kinetic sculptures\\nVisualized voices ...               561   \n",
              "18  The nights fall and skies fall\\nDown here we t...               264   \n",
              "19  The light of the sun - is so cold down here\\nM...               496   \n",
              "20  I love this world\\nAnd these people, the beaut...               521   \n",
              "21  There lies a body: cold, bloated and empty\\nLi...               540   \n",
              "22  Touch me!\\nI am a disease!\\nClean me!\\nImpriso...               281   \n",
              "23  Savour!\\nThe things that never were!\\nEscape!\\...               377   \n",
              "\n",
              "    Contains_letter Lyric_detected_language  \n",
              "7              True                      en  \n",
              "8              True                      en  \n",
              "9              True                      en  \n",
              "10             True                      en  \n",
              "11             True                      en  \n",
              "12             True                      en  \n",
              "13             True                      en  \n",
              "14             True                      en  \n",
              "15             True                      en  \n",
              "18             True                      en  \n",
              "19             True                      en  \n",
              "20             True                      en  \n",
              "21             True                      en  \n",
              "22             True                      en  \n",
              "23             True                      en  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-759aa4f0-4755-4ae1-aeee-6f11cfe85a43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lyric</th>\n",
              "      <th>Lyric_STR</th>\n",
              "      <th>No_of_Characters</th>\n",
              "      <th>Contains_letter</th>\n",
              "      <th>Lyric_detected_language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[GGFH cover]\\n\\n</td>\n",
              "      <td>[GGFH cover]\\n\\n</td>\n",
              "      <td>14</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[Originally performed by Bloodthorn]\\n\\nDrops ...</td>\n",
              "      <td>[Originally performed by Bloodthorn]\\n\\nDrops ...</td>\n",
              "      <td>685</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Electro eroticism\\nIntelligence is sexy\\nElect...</td>\n",
              "      <td>Electro eroticism\\nIntelligence is sexy\\nElect...</td>\n",
              "      <td>539</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Inhale/exhale\\nInhale the exhaled\\nInhale/exha...</td>\n",
              "      <td>Inhale/exhale\\nInhale the exhaled\\nInhale/exha...</td>\n",
              "      <td>502</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Under the dark sky we stand\\nUnder heavy rain ...</td>\n",
              "      <td>Under the dark sky we stand\\nUnder heavy rain ...</td>\n",
              "      <td>838</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Seducer sun shine on me\\nFamiliar scene, fever...</td>\n",
              "      <td>Seducer sun shine on me\\nFamiliar scene, fever...</td>\n",
              "      <td>551</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>The black iris devours pictures in silence\\nTh...</td>\n",
              "      <td>The black iris devours pictures in silence\\nTh...</td>\n",
              "      <td>722</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Night swells to distant spheres\\nSilent throat...</td>\n",
              "      <td>Night swells to distant spheres\\nSilent throat...</td>\n",
              "      <td>739</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Opulent kinetic sculptures\\nVisualized voices ...</td>\n",
              "      <td>Opulent kinetic sculptures\\nVisualized voices ...</td>\n",
              "      <td>561</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>The nights fall and skies fall\\nDown here we t...</td>\n",
              "      <td>The nights fall and skies fall\\nDown here we t...</td>\n",
              "      <td>264</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>The light of the sun - is so cold down here\\nM...</td>\n",
              "      <td>The light of the sun - is so cold down here\\nM...</td>\n",
              "      <td>496</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>I love this world\\nAnd these people, the beaut...</td>\n",
              "      <td>I love this world\\nAnd these people, the beaut...</td>\n",
              "      <td>521</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>There lies a body: cold, bloated and empty\\nLi...</td>\n",
              "      <td>There lies a body: cold, bloated and empty\\nLi...</td>\n",
              "      <td>540</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Touch me!\\nI am a disease!\\nClean me!\\nImpriso...</td>\n",
              "      <td>Touch me!\\nI am a disease!\\nClean me!\\nImpriso...</td>\n",
              "      <td>281</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Savour!\\nThe things that never were!\\nEscape!\\...</td>\n",
              "      <td>Savour!\\nThe things that never were!\\nEscape!\\...</td>\n",
              "      <td>377</td>\n",
              "      <td>True</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-759aa4f0-4755-4ae1-aeee-6f11cfe85a43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-759aa4f0-4755-4ae1-aeee-6f11cfe85a43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-759aa4f0-4755-4ae1-aeee-6f11cfe85a43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Removing non-english data\n",
        "\n",
        "data = data.drop(data[data['Lyric_detected_language'] != 'en'].index)\n",
        "\n",
        "data.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean from /n and other stufff \n",
        "global cnt_total, cnt_kept\n",
        "cnt_total, cnt_kept = 0, 0\n",
        "def check_line(text):\n",
        "  # cnt_total += 1\n",
        "  if len(text) < 5: return False\n",
        "  black_list = ['\\x03', '\\x05', '\\t', '\\n', '\\x0c', '\\x10', '\\x19', '#', '$', '%', '&', '(', ')', '*', '+', '<', '>', '_', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', '@', '[', '\\\\', ']', '^', '{', '|', '}', '~', '\\x7f', '\\xa0', '¤', '¦', '§', '©', '«', '¬', '\\xad', '®', '°', '±', 'µ', '¶', '·', '»', 'в', 'г', 'д', 'к', 'о', 'п', 'ш', 'щ', 'ё', 'ђ', 'ѓ', 'є', 'ї', 'љ', 'њ', 'ћ', 'ќ', 'ў', 'џ', 'ґ', '†', '‡', '•', '‰', '‹', '›', '€', '№', '™']\n",
        "  for ch in black_list:\n",
        "    if ch in text: return False\n",
        "  # cnt_kept += 1\n",
        "  return True\n",
        "\n",
        "def clean_line(text):\n",
        "  return re.sub(\"[^A-Za-z0-9\\ \\n]\",\"\",text.lower())\n",
        "  \n",
        "def clean_song(text):\n",
        "  lines = text.split('\\n')\n",
        "  lines = [clean_line(l) for l in lines if check_line(l)] \n",
        "  return ' : '.join(lines)\n",
        "\n"
      ],
      "metadata": {
        "id": "BvP3PdhOpCS6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Lyrics'] = data['Lyric_STR'].apply(clean_song)\n",
        "\n",
        "print(cnt_total, cnt_kept)"
      ],
      "metadata": {
        "id": "ywfBEtbuqM8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "949bad88-ecc0-43d5-955b-8856d4c6fde0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Lyrics'].head(5)"
      ],
      "metadata": {
        "id": "4_ElHkMRqtIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzjHqYbNXhpJ"
      },
      "source": [
        "The generation of text with RNN involves the following workflow.  \n",
        "\n",
        "<p style=\"background-color:#B3C5E3;font-family:newtimeroman;color:#444160;text-align:center;font-size:120%;\">Loading Data ➡️ Preprocessing ➡️ Building Mapping Dictionary ➡️ Building Model ➡️ Generating Text</p>\n",
        "\n",
        "As I have loaded and explored the data,  I will proceed further by pre-processing the text.  \n",
        "\n",
        "\n",
        "<a id=\"4\"></a>\n",
        "# <p style=\"background-color:#B291B6;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 60px;\">DATA PREPROCESSING</p>\n",
        "\n",
        "**In this section, I will be performing the following:**\n",
        "\n",
        "**Creating a Corpus of Lyrics text:** For the model, we need a sequence of the text string. I am creating a Corpus out of Lyrics column. \n",
        "\n",
        "**Removing the unrequired characters that may have sneaked in my text corpus:** The data cleaning process for NLP is crucial preprocessing. To do that, I look into the Corpus to check for what this Corpus is comprised of. That is, all the unique symbols present. After examining the Corpus, I will be eliminating any foreign language or irrelevant symbols from the Corpus. \n",
        "\n",
        "**Creating a dictionary to map characters and their indices:** The computer doesn’t understand the text. For the computer, the text is just a cluster of symbols. It works with numbers. So we create a dictionary to map each unique character in our Corpus to a number and vice versa. This will be used to encode and decode the information going in and getting out of the RNN\n",
        "\n",
        "**Splitting the corpus into smaller sentences of equal length:** Encoding and splitting the corpus into smaller sequences of equal length: At this point, Corpus contain only intended characters (i.e, lower cap English alphabets, Numbers and a few punctuations). We will encode this corpus and create small sequences of equal lengths of features and the corresponding targets. Each feature and target will contain the mapped index in the dictionary of the unique characters they signify. \n",
        "\n",
        "The labels are then resized and normalized. Whereas the targets are one-hot encoded. Ready to be sent to the RNN for the training, but before that let us built the RNN model. \n",
        "\n",
        "**Creating a Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "TM2uH6yUDHFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_1, data_2 = train_test_split(data, test_size=0.7)\n",
        "\n"
      ],
      "metadata": {
        "id": "-TnPxNgj_nnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into 2 halves\n",
        "\n",
        "# data_1 = data.iloc[:, :45369]"
      ],
      "metadata": {
        "id": "mCrfACeI-7oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data_1))"
      ],
      "metadata": {
        "id": "ddYC8uQeCvia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WMNf0UBLD-cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERs1F9sgjk-Q"
      },
      "outputs": [],
      "source": [
        "#Lining up all the lyrics to create corpus\n",
        "\n",
        "Corpus =' ; '.join([song.lower() for song in data_1.Lyrics])\n",
        "    \n",
        "# Corpus = Corpus.lower() #converting all alphabets to lowercase \n",
        "print(\"Number of unique characters:\", len(set(Corpus)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw6V6p2TjzCe"
      },
      "outputs": [],
      "source": [
        "#To See all the unique characters present in the Corpus\n",
        "print(\"The unique characters:\",sorted(set(Corpus)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySNGj0INXhpJ"
      },
      "outputs": [],
      "source": [
        "# data_1.Lyrics[5][:500]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data.to_csv('data_17NOV.csv', index=False)\n"
      ],
      "metadata": {
        "id": "4v__KkFK3JVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5jIqxW_XhpK"
      },
      "source": [
        "The total number of unique characters present in the Corpus clearly shows, that some of the foreign language scripts have sneaked in. I will take a look at all the characters present. I will then remove the unrequired characters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BXFSMnSXhpL"
      },
      "source": [
        "**Creating a list of sorted unique characters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3py1Z80XhpL"
      },
      "outputs": [],
      "source": [
        "# # Storing all the unique characters present in my corpus to bult a mapping dic. \n",
        "# symb = sorted(list(set(Corpus)))\n",
        "\n",
        "# L_corpus = len(Corpus) #length of corpus\n",
        "# L_symb = len(symb) #length of total unique characters\n",
        "\n",
        "# #Building dictionary to access the vocabulary from indices and vice versa\n",
        "# mapping = dict((c, i) for i, c in enumerate(symb))\n",
        "# reverse_mapping = dict((i, c) for i, c in enumerate(symb))\n",
        "\n",
        "# print(\"Total number of characters:\", L_corpus)\n",
        "# print(\"Number of unique characters:\", L_symb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQ3stetGXhpL"
      },
      "outputs": [],
      "source": [
        "# #Splitting the Corpus in equal length of strings and output target\n",
        "# length = 40\n",
        "# features = []\n",
        "# targets = []\n",
        "# for i in range(0, L_corpus//100 - length, 1):\n",
        "#     feature = Corpus[i:i + length]\n",
        "#     target = Corpus[i + length]\n",
        "#     features.append([[mapping[j]/ float(L_symb) for j in feature]])\n",
        "#     targets.append(mapping[target])\n",
        "    \n",
        "    \n",
        "# L_datapoints = len(targets)\n",
        "# print(\"Total number of sequences in the Corpus:\", L_datapoints)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT94BKLAXhpM"
      },
      "source": [
        "**Encoding the Labels and Targets**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "hddFEnjLV2Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmWtAfhxXhpM"
      },
      "outputs": [],
      "source": [
        "# # reshape X and normalize\n",
        "# X = (np.reshape(features, (L_datapoints, length, 1)))# / float(L_symb)\n",
        "\n",
        "# # one hot encode the output variable\n",
        "# y = np_utils.to_categorical(targets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y = np_utils.to_categorical(targets)"
      ],
      "metadata": {
        "id": "3-r4MIi4Evty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X.shape\n",
        "# # X[0]\n",
        "# y.shape"
      ],
      "metadata": {
        "id": "alqd_RISMcp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u26wJ2VnXhpM"
      },
      "source": [
        "<a id=\"5\"></a>\n",
        "# <p style=\"background-color:#B291B6;font-family:newtimeroman;font-size:150%;color:#444160;text-align:center;border-radius:20px 60px;\">MODEL BUILDING</p>\n",
        "\n",
        "\n",
        "Recurrent Neural Networks are pretty popular with generating text. In this project, I will be using a LSTM Model, an improved version of a standard recurrent neural network\n",
        "\n",
        "**Following steps are involved in the model building**\n",
        "\n",
        "* Initialising the Model\n",
        "* Defining by adding layers\n",
        "* Compiling the Model\n",
        "* Training the Model\n",
        "\n",
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OratBK70XhpM"
      },
      "outputs": [],
      "source": [
        "# #Initialising the Model\n",
        "\n",
        "# model = Sequential()\n",
        "# #Adding layers\n",
        "# model.add(LSTM(256, input_shape=(length, 1), return_sequences=True))\n",
        "# model.add(LSTM(256))\n",
        "# model.add(Dense(y.shape[1], activation='softmax'))\n",
        "# #Compiling the model for training  \n",
        "# opt = Adamax(learning_rate=0.01)\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "\n",
        "# #Model's Summary               \n",
        "# model.summary()\n",
        "# from tensorflow.python.client import device_lib\n",
        "# device_lib.list_local_devices()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBl1Esp1XhpN"
      },
      "outputs": [],
      "source": [
        "# #Training the Model\n",
        "# history = model.fit(X, y, batch_size=512, epochs=100, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kI2hfgNXhpN"
      },
      "outputs": [],
      "source": [
        "# from keras.models import load_model\n",
        "# #To be used later; I am saving the model \n",
        "# model.save(\"Lyrics_Generator.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uIEYKdjXhpN"
      },
      "source": [
        "<a id=\"6\"></a>\n",
        "# <p style=\"background-color:#B291B6;font-family:newtimeroman;font-size:150%;color:#444160;text-align:center;border-radius:20px 60px;\">EVALUATING MODELS</p>\n",
        "\n",
        "Now that I have my model trained on the songs lyrics let us see how it performs. I hope it creates some sensible song.\n",
        "\n",
        "**To evaluate my model, I shall be having a look at:**\n",
        "* The performance of the model via Learning Curves\n",
        "* The outcome text it generates\n",
        "\n",
        "**Plotting the learning curve for the loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVDp-fAIXhpN"
      },
      "outputs": [],
      "source": [
        "# history_df = pd.DataFrame(history.history)\n",
        "# #Plotting the learnings \n",
        "\n",
        "# fig = plt.figure(figsize=(15,4), facecolor=\"#B291B6\")\n",
        "# fig.suptitle(\"Learning Plot of Model for Loss\")\n",
        "# pl=sns.lineplot(data=history_df[\"loss\"],color=\"#444160\")\n",
        "# pl.set(ylabel =\"Training Loss\")\n",
        "# pl.set(xlabel =\"Epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB3TqdB5XhpO"
      },
      "source": [
        "**Generating the songs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86impOZDXhpO"
      },
      "outputs": [],
      "source": [
        "# # The function to generate text from model\n",
        "# def Lyrics_Generator(starter,Ch_count): #,temperature=1.0):\n",
        "#     generated= \"\"\n",
        "#     starter = starter \n",
        "#     seed=[mapping[char] for char in starter]\n",
        "#     generated += starter \n",
        "#     # Generating new text of given length\n",
        "#     for i in range(Ch_count):\n",
        "#         seed=[mapping[char] for char in starter]\n",
        "#         x_pred = np.reshape(seed, (1, len(seed), 1))\n",
        "#         x_pred = x_pred/ float(L_symb)\n",
        "#         prediction = model.predict(x_pred, verbose=0)[0]  \n",
        "#         # Getting the index of the next most probable index\n",
        "#         prediction = np.asarray(prediction).astype('float64')\n",
        "#         prediction = np.log(prediction) / 1.0 \n",
        "#         exp_preds = np.exp(prediction)\n",
        "#         prediction = exp_preds / np.sum(exp_preds)\n",
        "#         probas = np.random.multinomial(1, prediction, 1)\n",
        "#         index = np.argmax(prediction)\n",
        "#         next_char = reverse_mapping[index]  \n",
        "#         # Generating new text\n",
        "#         generated += next_char\n",
        "#         starter = starter[1:] + next_char\n",
        "       \n",
        "    # return generated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFeTXjaGXhpO"
      },
      "source": [
        "Let us finally see the outcome by putting a seed in from one of my old blogposts [blogpost](https://karnikakapoor.blogspot.com/2017/04/killers-confession.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk-lwIrMXhpO"
      },
      "outputs": [],
      "source": [
        "# #Generating a song from the model\n",
        "# song_1 = Lyrics_Generator(\"the shoe shrunk and the school belt got \", 400)\n",
        "# #Let's have a look at the song\n",
        "# # My_song(song_1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# song_1"
      ],
      "metadata": {
        "id": "DcgKk7slQUHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBUhBvQMXhpP"
      },
      "source": [
        "Another song generated by a seed of the lyrics of a song that's stuck in my head today. (Sunflower by Shannon Purser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eto0QEk-XhpP"
      },
      "outputs": [],
      "source": [
        "# #Generating a song from the model using a song out of the corpus\n",
        "# song_2 = Lyrics_Generator(\"i'm a sunflower, a little funny\", 400)\n",
        "# #Let's have a look at the song\n",
        "# My_song(song_2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data.to_csv(\"data_processed.csv\", index=False, header=True)"
      ],
      "metadata": {
        "id": "c2bO7ZqQmEvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # =====================\n",
        "\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # keras module for building LSTM \n",
        "# from keras_preprocessing.sequence import pad_sequences\n",
        "# from tensorflow.keras.layers import Embedding, Dropout, LSTM, Dense, Bidirectional \n",
        "# from keras.preprocessing.text import Tokenizer\n",
        "# from keras.callbacks import EarlyStopping\n",
        "# from keras.models import Sequential"
      ],
      "metadata": {
        "id": "L1oQ33SZiZPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(\"/content/data_processed.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "d0LOTzL5ieMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.head(1)"
      ],
      "metadata": {
        "id": "MLgUitfCpTM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch import nn\n",
        "# import torch.nn.functional as F\n",
        "# from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "3tQq6Unq5Gki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DP_text = data['Lyric_STR'].str.cat(sep='\\n').lower()"
      ],
      "metadata": {
        "id": "XaokU0rT6tOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Corpus[:100])\n",
        "print('corpus length:', len(Corpus))"
      ],
      "metadata": {
        "id": "M7wdVDZ54dv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(Corpus)))\n",
        "print(chars)\n",
        "print('total chars:', len(chars))"
      ],
      "metadata": {
        "id": "2fx67e004iEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print(char_to_int)"
      ],
      "metadata": {
        "id": "_4weRxzH4oGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "seq_length = 50 # The sentence window size\n",
        "step = 1 # The steps between the windows\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "# Create Target and sentences window\n",
        "for i in range(0, len(Corpus) - seq_length, step):\n",
        "    sentences.append(Corpus[i: i + seq_length]) # range from current index to sequence length charaters\n",
        "    next_chars.append(Corpus[i + seq_length]) # the next character\n",
        "\n",
        "sentences = np.array(sentences)\n",
        "next_chars = np.array(next_chars)\n",
        "\n",
        "#Print Sentence Window and next charaters\n",
        "print('Sentence Window')\n",
        "print (sentences[:5])\n",
        "print('Target charaters')\n",
        "print (next_chars[:5])\n",
        "print('Number of sequences:', len(sentences))"
      ],
      "metadata": {
        "id": "W2moITm25AAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getdata(sentences, next_chars):\n",
        "    X = np.zeros((len(sentences),seq_length))\n",
        "    y = np.zeros((len(sentences)))\n",
        "    for i in range(len(sentences)):\n",
        "        sentence = sentences[i]\n",
        "        for t, char in enumerate(sentence):\n",
        "            X[i, t] = char_to_int[char]\n",
        "        y[i] = char_to_int[next_chars[i]]\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "KbZRE3I95C6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x,train_y = getdata(sentences, next_chars)\n",
        "print('Shape of training_x:', train_x.shape)\n",
        "print('Shape of training_y:', train_y.shape)"
      ],
      "metadata": {
        "id": "tyLaBoIz5yWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, n_vocab, hidden_dim, embedding_dim, dropout=0.2, **kwargs):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, dropout=dropout, num_layers=2)\n",
        "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def forward(self, seq_in):\n",
        "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
        "        embedded = self.embeddings(seq_in.t())\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        # Only need to keep the last character\n",
        "        ht=lstm_out[-1]\n",
        "        out = self.fc(ht)\n",
        "        return out"
      ],
      "metadata": {
        "id": "GmoWjCO056YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(train_x, dtype=torch.long).cuda()\n",
        "Y_train_tensor = torch.tensor(train_y, dtype=torch.long).cuda()"
      ],
      "metadata": {
        "id": "b265fYW-KTL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = 128)"
      ],
      "metadata": {
        "id": "ykVN0_1xKXmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleLSTM(len(chars), 256, 256, char_to_int=char_to_int, int_to_char=int_to_char)\n",
        "model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002) # Using Adam optimizer"
      ],
      "metadata": {
        "id": "-ZhPMvd_KcWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(chars))"
      ],
      "metadata": {
        "id": "nqKMj17EKf2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time # Add time counter\n",
        "avg_losses_f = []\n",
        "n_epochs = 20\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    avg_loss = 0.\n",
        "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        y_pred = model(x_batch)\n",
        "\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        avg_loss+= loss.item() / len(train_loader)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
        "        epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
        "\n",
        "    avg_losses_f.append(avg_loss)\n",
        "\n",
        "print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))"
      ],
      "metadata": {
        "id": "GgX_ZUE9KkxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "lzH2DG6PKpwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'i read in the news that the average man please kis'\n",
        "\n",
        "variance = 0.3\n",
        "generated = ''\n",
        "original = sentence\n",
        "window = sentence\n",
        "\n",
        "for i in range(400):\n",
        "    x = np.zeros((1, seq_length))\n",
        "    for t, char in enumerate(window):\n",
        "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
        "\n",
        "    x_in = Variable(torch.LongTensor(x).cuda())\n",
        "    pred = model(x_in)\n",
        "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
        "    next_index = sample(pred, variance)\n",
        "    next_char = int_to_char[next_index] # index to char\n",
        "\n",
        "    generated += next_char\n",
        "    window = window[1:] + next_char # Update Window for next char predict\n",
        "\n",
        "print(original + generated)"
      ],
      "metadata": {
        "id": "1miKuc02Kwwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, f'/content/tims.model')"
      ],
      "metadata": {
        "id": "iXvsVS9DyGWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1AYWTeXqCuNm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}