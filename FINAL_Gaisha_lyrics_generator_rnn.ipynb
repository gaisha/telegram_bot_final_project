{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtjKCzB1XhpF"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string, os\n",
        "import re\n",
        "import random\n",
        "import io\n",
        "import sys\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u26wJ2VnXhpM"
      },
      "source": [
        "**MODEL BUILDING**\n",
        "\n",
        "\n",
        "Recurrent Neural Networks are pretty popular with generating text. In this project, I will be using a LSTM Model, an improved version of a standard recurrent neural network\n",
        "\n",
        "**Following steps are involved in the model building**\n",
        "\n",
        "* Initialising the Model\n",
        "* Training the Model\n",
        "* Checking  output\n",
        "\n",
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/LSML2/data.txt', 'r') as file:\n",
        "    Corpus = file.read()\n",
        "\n",
        "\n",
        "print(Corpus[:100])\n",
        "print('corpus length:', len(Corpus))"
      ],
      "metadata": {
        "id": "M7wdVDZ54dv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03879d4d-c54b-4044-cbb9-f2fea31a0d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "every man will ask the questions and every man will suffer blame and loss  every day you die a littl\n",
            "corpus length: 44806010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(Corpus)))\n"
      ],
      "metadata": {
        "id": "2fx67e004iEH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n"
      ],
      "metadata": {
        "id": "_4weRxzH4oGk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "seq_length = 50 # The sentence window size\n",
        "step = 1 # The steps between the windows\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "# Create Target and sentences window\n",
        "for i in range(0, len(Corpus) - seq_length, step):\n",
        "    sentences.append(Corpus[i: i + seq_length]) # range from current index to sequence length charaters\n",
        "    next_chars.append(Corpus[i + seq_length]) # the next character\n",
        "\n",
        "sentences = np.array(sentences)\n",
        "next_chars = np.array(next_chars)\n",
        "\n",
        "#Print Sentence Window and next charaters\n",
        "print('Sentence Window')\n",
        "print (sentences[:5])\n",
        "print('Target charaters')\n",
        "print (next_chars[:5])\n",
        "print('Number of sequences:', len(sentences))"
      ],
      "metadata": {
        "id": "W2moITm25AAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b729af1e-21af-4a26-b2dc-d9b541b44e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Window\n",
            "['every man will ask the questions and every man wil'\n",
            " 'very man will ask the questions and every man will'\n",
            " 'ery man will ask the questions and every man will '\n",
            " 'ry man will ask the questions and every man will s'\n",
            " 'y man will ask the questions and every man will su']\n",
            "Target charaters\n",
            "['l' ' ' 's' 'u' 'f']\n",
            "Number of sequences: 44805960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getdata(sentences, next_chars):\n",
        "    X = np.zeros((len(sentences),seq_length))\n",
        "    y = np.zeros((len(sentences)))\n",
        "    for i in range(len(sentences)):\n",
        "        sentence = sentences[i]\n",
        "        for t, char in enumerate(sentence):\n",
        "            X[i, t] = char_to_int[char]\n",
        "        y[i] = char_to_int[next_chars[i]]\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "KbZRE3I95C6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x,train_y = getdata(sentences, next_chars)\n",
        "print('Shape of training_x:', train_x.shape)\n",
        "print('Shape of training_y:', train_y.shape)"
      ],
      "metadata": {
        "id": "tyLaBoIz5yWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beab4b09-c345-4113-986d-ab17635d03da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training_x: (44805960, 50)\n",
            "Shape of training_y: (44805960,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, n_vocab, hidden_dim, embedding_dim, dropout=0.2, **kwargs):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, dropout=dropout, num_layers=2)\n",
        "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def forward(self, seq_in):\n",
        "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
        "        embedded = self.embeddings(seq_in.t())\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        # Only need to keep the last character\n",
        "        ht=lstm_out[-1]\n",
        "        out = self.fc(ht)\n",
        "        return out"
      ],
      "metadata": {
        "id": "GmoWjCO056YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(train_x, dtype=torch.long).cuda()\n",
        "Y_train_tensor = torch.tensor(train_y, dtype=torch.long).cuda()"
      ],
      "metadata": {
        "id": "b265fYW-KTL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = 128)"
      ],
      "metadata": {
        "id": "ykVN0_1xKXmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleLSTM(len(chars), 256, 256, char_to_int=char_to_int, int_to_char=int_to_char)\n",
        "model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002) # Using Adam optimizer"
      ],
      "metadata": {
        "id": "-ZhPMvd_KcWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training part**\n"
      ],
      "metadata": {
        "id": "0HIjariQE_n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time # Add time counter\n",
        "avg_losses_f = []\n",
        "n_epochs = 20\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    avg_loss = 0.\n",
        "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        y_pred = model(x_batch)\n",
        "\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        avg_loss+= loss.item() / len(train_loader)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
        "        epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
        "\n",
        "    avg_losses_f.append(avg_loss)\n",
        "\n",
        "print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))"
      ],
      "metadata": {
        "id": "GgX_ZUE9KkxN"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking  output**"
      ],
      "metadata": {
        "id": "_qeaMT4fExKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "lzH2DG6PKpwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Wait until the reaper takes my life Never gonna get me out alive'\n",
        "start_text = ''.join(sym.lower() for sym in sentence if sym.lower() in char_to_int)[:seq_length]\n",
        "variance = 0.3\n",
        "generated = ''\n",
        "original = start_text\n",
        "window = start_text\n",
        "\n",
        "for i in range(400):\n",
        "    x = np.zeros((1, seq_length))\n",
        "    for t, char in enumerate(window):\n",
        "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
        "\n",
        "    x_in = Variable(torch.LongTensor(x))\n",
        "    pred = model(x_in)\n",
        "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
        "    next_index = sample(pred, variance)\n",
        "    next_char = int_to_char[next_index] # index to char\n",
        "\n",
        "    generated += next_char\n",
        "    window = window[1:] + next_char # Update Window for next char predict\n",
        "\n",
        "print(original + generated)"
      ],
      "metadata": {
        "id": "1miKuc02Kwwx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a9bb06-07fb-4d4c-be9a-3cc97d106fb1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wait until the reaper takes my life never gonna get you\n",
            "as think for yourself\n",
            "'cause i won't be the day when you make me cry\n",
            "you know it's a lie\n",
            "'cause that'll be the day\n",
            "when you tree bompa bom\n",
            "sail that weight and far away, yeah young blood\n",
            "i can't get you out of my mind\n",
            "i tried to be ready to love, babe\n",
            "well what'll be the day\n",
            "when you treat me so unkind\n",
            "what's your name\n",
            "what's should i love you\n",
            "and she done me some on comesonifed to lost me\n",
            "l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), f'/content/trained_model.model')"
      ],
      "metadata": {
        "id": "iXvsVS9DyGWS"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAiii0Nwww12"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "7uIEYKdjXhpN"
      ]
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}